{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from datetime import datetime\n",
    "from sklearn import metrics\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['the extracted feature'] = df['the extracted feature'].apply(lambda x: np.fromstring(x[1:-1], sep=' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.array(df['the extracted feature'].tolist())\n",
    "y=np.array(df['class'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(587, 40) (587,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape , y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelencoder=LabelEncoder()\n",
    "y=to_categorical(labelencoder.fit_transform(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((469, 40), (118, 40), (469, 10), (118, 10))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.regularizers import l1\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import BatchNormalization, LeakyReLU\n",
    "\n",
    "num_labels = y.shape[1]\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(100, input_dim=40, kernel_regularizer=l1(0.001)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=0.05))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(200, kernel_regularizer=l1(0.001)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=0.05))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(100, kernel_regularizer=l1(0.001)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=0.05))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(num_labels, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 100)               4100      \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 100)              400       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 100)               0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 200)               20200     \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 200)              800       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_4 (LeakyReLU)   (None, 200)               0         \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 200)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 100)               20100     \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 100)              400       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_5 (LeakyReLU)   (None, 100)               0         \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 47,010\n",
      "Trainable params: 46,210\n",
      "Non-trainable params: 800\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 2.9860 - accuracy: 0.3750\n",
      "Epoch 1: val_loss improved from inf to 2.69833, saving model to saved_models/audio_classification.hdf5\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 3.1470 - accuracy: 0.4371 - val_loss: 2.6983 - val_accuracy: 0.5254\n",
      "Epoch 2/100\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 3.1134 - accuracy: 0.3125\n",
      "Epoch 2: val_loss improved from 2.69833 to 2.66870, saving model to saved_models/audio_classification.hdf5\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 2.9996 - accuracy: 0.4733 - val_loss: 2.6687 - val_accuracy: 0.4831\n",
      "Epoch 3/100\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 3.4545 - accuracy: 0.3750\n",
      "Epoch 3: val_loss improved from 2.66870 to 2.66209, saving model to saved_models/audio_classification.hdf5\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 3.0218 - accuracy: 0.5053 - val_loss: 2.6621 - val_accuracy: 0.4661\n",
      "Epoch 4/100\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 2.8774 - accuracy: 0.5625\n",
      "Epoch 4: val_loss improved from 2.66209 to 2.65577, saving model to saved_models/audio_classification.hdf5\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 2.8576 - accuracy: 0.5139 - val_loss: 2.6558 - val_accuracy: 0.4915\n",
      "Epoch 5/100\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 2.8834 - accuracy: 0.3750\n",
      "Epoch 5: val_loss improved from 2.65577 to 2.64290, saving model to saved_models/audio_classification.hdf5\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 2.8207 - accuracy: 0.5160 - val_loss: 2.6429 - val_accuracy: 0.4915\n",
      "Epoch 6/100\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 2.8025 - accuracy: 0.7500\n",
      "Epoch 6: val_loss improved from 2.64290 to 2.62297, saving model to saved_models/audio_classification.hdf5\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 2.7804 - accuracy: 0.5032 - val_loss: 2.6230 - val_accuracy: 0.5000\n",
      "Epoch 7/100\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 2.9301 - accuracy: 0.3750\n",
      "Epoch 7: val_loss improved from 2.62297 to 2.58629, saving model to saved_models/audio_classification.hdf5\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 2.7688 - accuracy: 0.5117 - val_loss: 2.5863 - val_accuracy: 0.5000\n",
      "Epoch 8/100\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 2.9803 - accuracy: 0.4375\n",
      "Epoch 8: val_loss improved from 2.58629 to 2.54349, saving model to saved_models/audio_classification.hdf5\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 2.7453 - accuracy: 0.5139 - val_loss: 2.5435 - val_accuracy: 0.5000\n",
      "Epoch 9/100\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 2.5159 - accuracy: 0.6250\n",
      "Epoch 9: val_loss improved from 2.54349 to 2.51601, saving model to saved_models/audio_classification.hdf5\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 2.7440 - accuracy: 0.4947 - val_loss: 2.5160 - val_accuracy: 0.5254\n",
      "Epoch 10/100\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 2.7597 - accuracy: 0.6250\n",
      "Epoch 10: val_loss improved from 2.51601 to 2.47850, saving model to saved_models/audio_classification.hdf5\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 2.6832 - accuracy: 0.5586 - val_loss: 2.4785 - val_accuracy: 0.5169\n",
      "Epoch 11/100\n",
      "22/30 [=====================>........] - ETA: 0s - loss: 2.6181 - accuracy: 0.5653\n",
      "Epoch 11: val_loss improved from 2.47850 to 2.44372, saving model to saved_models/audio_classification.hdf5\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 2.6022 - accuracy: 0.5714 - val_loss: 2.4437 - val_accuracy: 0.5508\n",
      "Epoch 12/100\n",
      "19/30 [==================>...........] - ETA: 0s - loss: 2.5833 - accuracy: 0.5691\n",
      "Epoch 12: val_loss improved from 2.44372 to 2.40711, saving model to saved_models/audio_classification.hdf5\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 2.6015 - accuracy: 0.5714 - val_loss: 2.4071 - val_accuracy: 0.5847\n",
      "Epoch 13/100\n",
      "20/30 [===================>..........] - ETA: 0s - loss: 2.6739 - accuracy: 0.5219\n",
      "Epoch 13: val_loss improved from 2.40711 to 2.38182, saving model to saved_models/audio_classification.hdf5\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 2.6601 - accuracy: 0.5245 - val_loss: 2.3818 - val_accuracy: 0.5932\n",
      "Epoch 14/100\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 2.5723 - accuracy: 0.5575\n",
      "Epoch 14: val_loss improved from 2.38182 to 2.33210, saving model to saved_models/audio_classification.hdf5\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 2.5607 - accuracy: 0.5608 - val_loss: 2.3321 - val_accuracy: 0.6186\n",
      "Epoch 15/100\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 2.6445 - accuracy: 0.4375\n",
      "Epoch 15: val_loss improved from 2.33210 to 2.30233, saving model to saved_models/audio_classification.hdf5\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 2.5089 - accuracy: 0.5672 - val_loss: 2.3023 - val_accuracy: 0.6271\n",
      "Epoch 16/100\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 2.2211 - accuracy: 0.6875\n",
      "Epoch 16: val_loss improved from 2.30233 to 2.27582, saving model to saved_models/audio_classification.hdf5\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 2.4458 - accuracy: 0.6119 - val_loss: 2.2758 - val_accuracy: 0.6356\n",
      "Epoch 17/100\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 2.2736 - accuracy: 0.6250\n",
      "Epoch 17: val_loss improved from 2.27582 to 2.25071, saving model to saved_models/audio_classification.hdf5\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 2.5343 - accuracy: 0.5544 - val_loss: 2.2507 - val_accuracy: 0.5847\n",
      "Epoch 18/100\n",
      " 7/30 [======>.......................] - ETA: 0s - loss: 2.4547 - accuracy: 0.6071\n",
      "Epoch 18: val_loss improved from 2.25071 to 2.22160, saving model to saved_models/audio_classification.hdf5\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 2.4677 - accuracy: 0.5842 - val_loss: 2.2216 - val_accuracy: 0.6102\n",
      "Epoch 19/100\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 2.6686 - accuracy: 0.6250\n",
      "Epoch 19: val_loss improved from 2.22160 to 2.19583, saving model to saved_models/audio_classification.hdf5\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 2.4218 - accuracy: 0.5693 - val_loss: 2.1958 - val_accuracy: 0.6441\n",
      "Epoch 20/100\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 2.4048 - accuracy: 0.6250\n",
      "Epoch 20: val_loss improved from 2.19583 to 2.17236, saving model to saved_models/audio_classification.hdf5\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 2.4354 - accuracy: 0.5864 - val_loss: 2.1724 - val_accuracy: 0.6525\n",
      "Epoch 21/100\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 2.6792 - accuracy: 0.6250\n",
      "Epoch 21: val_loss improved from 2.17236 to 2.14082, saving model to saved_models/audio_classification.hdf5\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 2.4027 - accuracy: 0.6098 - val_loss: 2.1408 - val_accuracy: 0.6610\n",
      "Epoch 22/100\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 2.2324 - accuracy: 0.6875\n",
      "Epoch 22: val_loss improved from 2.14082 to 2.11102, saving model to saved_models/audio_classification.hdf5\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 2.3714 - accuracy: 0.6183 - val_loss: 2.1110 - val_accuracy: 0.6695\n",
      "Epoch 23/100\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 2.2853 - accuracy: 0.6250\n",
      "Epoch 23: val_loss improved from 2.11102 to 2.07362, saving model to saved_models/audio_classification.hdf5\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 2.3829 - accuracy: 0.5864 - val_loss: 2.0736 - val_accuracy: 0.6949\n",
      "Epoch 24/100\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 1.9971 - accuracy: 0.7500\n",
      "Epoch 24: val_loss improved from 2.07362 to 2.04025, saving model to saved_models/audio_classification.hdf5\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 2.3410 - accuracy: 0.5821 - val_loss: 2.0403 - val_accuracy: 0.6949\n",
      "Epoch 25/100\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 2.3441 - accuracy: 0.6250\n",
      "Epoch 25: val_loss improved from 2.04025 to 2.00383, saving model to saved_models/audio_classification.hdf5\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 2.3147 - accuracy: 0.6375 - val_loss: 2.0038 - val_accuracy: 0.7203\n",
      "Epoch 26/100\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 2.2818 - accuracy: 0.5625\n",
      "Epoch 26: val_loss improved from 2.00383 to 1.99636, saving model to saved_models/audio_classification.hdf5\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 2.3006 - accuracy: 0.6119 - val_loss: 1.9964 - val_accuracy: 0.7288\n",
      "Epoch 27/100\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 2.0631 - accuracy: 0.8125\n",
      "Epoch 27: val_loss improved from 1.99636 to 1.96838, saving model to saved_models/audio_classification.hdf5\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 2.2895 - accuracy: 0.5928 - val_loss: 1.9684 - val_accuracy: 0.7373\n",
      "Epoch 28/100\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 2.4038 - accuracy: 0.6250\n",
      "Epoch 28: val_loss improved from 1.96838 to 1.95824, saving model to saved_models/audio_classification.hdf5\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 2.2809 - accuracy: 0.6183 - val_loss: 1.9582 - val_accuracy: 0.7203\n",
      "Epoch 29/100\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 2.1510 - accuracy: 0.6250\n",
      "Epoch 29: val_loss improved from 1.95824 to 1.92157, saving model to saved_models/audio_classification.hdf5\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 2.1990 - accuracy: 0.6631 - val_loss: 1.9216 - val_accuracy: 0.7373\n",
      "Epoch 30/100\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 2.6633 - accuracy: 0.5625\n",
      "Epoch 30: val_loss improved from 1.92157 to 1.89776, saving model to saved_models/audio_classification.hdf5\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 2.2603 - accuracy: 0.6119 - val_loss: 1.8978 - val_accuracy: 0.7373\n",
      "Epoch 31/100\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 2.2759 - accuracy: 0.6250\n",
      "Epoch 31: val_loss improved from 1.89776 to 1.87222, saving model to saved_models/audio_classification.hdf5\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 2.1642 - accuracy: 0.6823 - val_loss: 1.8722 - val_accuracy: 0.7712\n",
      "Epoch 32/100\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 2.1819 - accuracy: 0.6875\n",
      "Epoch 32: val_loss improved from 1.87222 to 1.85348, saving model to saved_models/audio_classification.hdf5\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 2.2037 - accuracy: 0.6354 - val_loss: 1.8535 - val_accuracy: 0.7797\n",
      "Epoch 33/100\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 2.0254 - accuracy: 0.8125\n",
      "Epoch 33: val_loss improved from 1.85348 to 1.82372, saving model to saved_models/audio_classification.hdf5\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 2.1320 - accuracy: 0.6525 - val_loss: 1.8237 - val_accuracy: 0.7881\n",
      "Epoch 34/100\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 2.4411 - accuracy: 0.5625\n",
      "Epoch 34: val_loss improved from 1.82372 to 1.80904, saving model to saved_models/audio_classification.hdf5\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 2.1204 - accuracy: 0.6482 - val_loss: 1.8090 - val_accuracy: 0.8051\n",
      "Epoch 35/100\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 2.0947 - accuracy: 0.6875\n",
      "Epoch 35: val_loss improved from 1.80904 to 1.79740, saving model to saved_models/audio_classification.hdf5\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 2.1489 - accuracy: 0.6461 - val_loss: 1.7974 - val_accuracy: 0.7881\n",
      "Epoch 36/100\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 1.9578 - accuracy: 0.7500\n",
      "Epoch 36: val_loss improved from 1.79740 to 1.77895, saving model to saved_models/audio_classification.hdf5\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 2.0970 - accuracy: 0.6525 - val_loss: 1.7790 - val_accuracy: 0.7797\n",
      "Epoch 37/100\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 1.9229 - accuracy: 0.7500\n",
      "Epoch 37: val_loss improved from 1.77895 to 1.74424, saving model to saved_models/audio_classification.hdf5\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 2.0889 - accuracy: 0.6418 - val_loss: 1.7442 - val_accuracy: 0.8051\n",
      "Epoch 38/100\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 1.8997 - accuracy: 0.8125\n",
      "Epoch 38: val_loss improved from 1.74424 to 1.72692, saving model to saved_models/audio_classification.hdf5\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 2.0994 - accuracy: 0.6503 - val_loss: 1.7269 - val_accuracy: 0.8136\n",
      "Epoch 39/100\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 2.1263 - accuracy: 0.5000\n",
      "Epoch 39: val_loss improved from 1.72692 to 1.70685, saving model to saved_models/audio_classification.hdf5\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 2.0886 - accuracy: 0.6674 - val_loss: 1.7068 - val_accuracy: 0.8051\n",
      "Epoch 40/100\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 1.9172 - accuracy: 0.6875\n",
      "Epoch 40: val_loss improved from 1.70685 to 1.69802, saving model to saved_models/audio_classification.hdf5\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.9859 - accuracy: 0.6866 - val_loss: 1.6980 - val_accuracy: 0.8220\n",
      "Epoch 41/100\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 2.0841 - accuracy: 0.6250\n",
      "Epoch 41: val_loss improved from 1.69802 to 1.66774, saving model to saved_models/audio_classification.hdf5\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.9888 - accuracy: 0.6994 - val_loss: 1.6677 - val_accuracy: 0.8305\n",
      "Epoch 42/100\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 2.1182 - accuracy: 0.6875\n",
      "Epoch 42: val_loss improved from 1.66774 to 1.66189, saving model to saved_models/audio_classification.hdf5\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 2.0493 - accuracy: 0.6439 - val_loss: 1.6619 - val_accuracy: 0.8559\n",
      "Epoch 43/100\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 2.1231 - accuracy: 0.5625\n",
      "Epoch 43: val_loss improved from 1.66189 to 1.65543, saving model to saved_models/audio_classification.hdf5\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 2.0620 - accuracy: 0.6610 - val_loss: 1.6554 - val_accuracy: 0.8475\n",
      "Epoch 44/100\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 2.2610 - accuracy: 0.4375\n",
      "Epoch 44: val_loss improved from 1.65543 to 1.63415, saving model to saved_models/audio_classification.hdf5\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 2.0101 - accuracy: 0.6674 - val_loss: 1.6342 - val_accuracy: 0.8390\n",
      "Epoch 45/100\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 1.7975 - accuracy: 0.7500\n",
      "Epoch 45: val_loss improved from 1.63415 to 1.60835, saving model to saved_models/audio_classification.hdf5\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.9195 - accuracy: 0.7313 - val_loss: 1.6083 - val_accuracy: 0.8390\n",
      "Epoch 46/100\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 1.7662 - accuracy: 0.7500\n",
      "Epoch 46: val_loss improved from 1.60835 to 1.58079, saving model to saved_models/audio_classification.hdf5\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.9351 - accuracy: 0.6908 - val_loss: 1.5808 - val_accuracy: 0.8390\n",
      "Epoch 47/100\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 1.8542 - accuracy: 0.7500\n",
      "Epoch 47: val_loss improved from 1.58079 to 1.56983, saving model to saved_models/audio_classification.hdf5\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.9552 - accuracy: 0.6908 - val_loss: 1.5698 - val_accuracy: 0.8475\n",
      "Epoch 48/100\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 1.7664 - accuracy: 0.6875\n",
      "Epoch 48: val_loss improved from 1.56983 to 1.55063, saving model to saved_models/audio_classification.hdf5\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.9159 - accuracy: 0.6951 - val_loss: 1.5506 - val_accuracy: 0.8559\n",
      "Epoch 49/100\n",
      " 3/30 [==>...........................] - ETA: 0s - loss: 1.8071 - accuracy: 0.6875\n",
      "Epoch 49: val_loss improved from 1.55063 to 1.52445, saving model to saved_models/audio_classification.hdf5\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.8483 - accuracy: 0.7186 - val_loss: 1.5244 - val_accuracy: 0.8644\n",
      "Epoch 50/100\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 1.6957 - accuracy: 0.7500\n",
      "Epoch 50: val_loss did not improve from 1.52445\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.9415 - accuracy: 0.6674 - val_loss: 1.5362 - val_accuracy: 0.8559\n",
      "Epoch 51/100\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 1.4984 - accuracy: 0.8750\n",
      "Epoch 51: val_loss improved from 1.52445 to 1.52254, saving model to saved_models/audio_classification.hdf5\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.8995 - accuracy: 0.7015 - val_loss: 1.5225 - val_accuracy: 0.8644\n",
      "Epoch 52/100\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 1.7225 - accuracy: 0.8125\n",
      "Epoch 52: val_loss improved from 1.52254 to 1.51559, saving model to saved_models/audio_classification.hdf5\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.8946 - accuracy: 0.6802 - val_loss: 1.5156 - val_accuracy: 0.8983\n",
      "Epoch 53/100\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 1.9512 - accuracy: 0.6250\n",
      "Epoch 53: val_loss did not improve from 1.51559\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 1.8640 - accuracy: 0.7079 - val_loss: 1.5281 - val_accuracy: 0.8644\n",
      "Epoch 54/100\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 1.8673 - accuracy: 0.6250\n",
      "Epoch 54: val_loss improved from 1.51559 to 1.50140, saving model to saved_models/audio_classification.hdf5\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.8757 - accuracy: 0.6866 - val_loss: 1.5014 - val_accuracy: 0.8898\n",
      "Epoch 55/100\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 2.0572 - accuracy: 0.5625\n",
      "Epoch 55: val_loss improved from 1.50140 to 1.48437, saving model to saved_models/audio_classification.hdf5\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.8093 - accuracy: 0.7420 - val_loss: 1.4844 - val_accuracy: 0.8814\n",
      "Epoch 56/100\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 1.9332 - accuracy: 0.6875\n",
      "Epoch 56: val_loss improved from 1.48437 to 1.47703, saving model to saved_models/audio_classification.hdf5\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.9282 - accuracy: 0.6716 - val_loss: 1.4770 - val_accuracy: 0.8898\n",
      "Epoch 57/100\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 1.9993 - accuracy: 0.6250\n",
      "Epoch 57: val_loss improved from 1.47703 to 1.46620, saving model to saved_models/audio_classification.hdf5\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.7922 - accuracy: 0.7186 - val_loss: 1.4662 - val_accuracy: 0.8814\n",
      "Epoch 58/100\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 1.5899 - accuracy: 0.7500\n",
      "Epoch 58: val_loss improved from 1.46620 to 1.44598, saving model to saved_models/audio_classification.hdf5\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.8033 - accuracy: 0.7228 - val_loss: 1.4460 - val_accuracy: 0.9068\n",
      "Epoch 59/100\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 1.7329 - accuracy: 0.7500\n",
      "Epoch 59: val_loss did not improve from 1.44598\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.8236 - accuracy: 0.7015 - val_loss: 1.4496 - val_accuracy: 0.8983\n",
      "Epoch 60/100\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 1.7236 - accuracy: 0.7500\n",
      "Epoch 60: val_loss improved from 1.44598 to 1.41305, saving model to saved_models/audio_classification.hdf5\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.8072 - accuracy: 0.7292 - val_loss: 1.4130 - val_accuracy: 0.8898\n",
      "Epoch 61/100\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 1.7980 - accuracy: 0.7500\n",
      "Epoch 61: val_loss improved from 1.41305 to 1.39066, saving model to saved_models/audio_classification.hdf5\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.7905 - accuracy: 0.7143 - val_loss: 1.3907 - val_accuracy: 0.8898\n",
      "Epoch 62/100\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 1.7500 - accuracy: 0.6875\n",
      "Epoch 62: val_loss did not improve from 1.39066\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 1.7915 - accuracy: 0.7228 - val_loss: 1.4041 - val_accuracy: 0.9068\n",
      "Epoch 63/100\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 1.6690 - accuracy: 0.7500\n",
      "Epoch 63: val_loss did not improve from 1.39066\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 1.8003 - accuracy: 0.7313 - val_loss: 1.4003 - val_accuracy: 0.8898\n",
      "Epoch 64/100\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 1.5215 - accuracy: 0.8125\n",
      "Epoch 64: val_loss improved from 1.39066 to 1.35964, saving model to saved_models/audio_classification.hdf5\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.7435 - accuracy: 0.7399 - val_loss: 1.3596 - val_accuracy: 0.9153\n",
      "Epoch 65/100\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 1.9023 - accuracy: 0.7500\n",
      "Epoch 65: val_loss did not improve from 1.35964\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.7547 - accuracy: 0.7441 - val_loss: 1.3619 - val_accuracy: 0.9237\n",
      "Epoch 66/100\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 1.4905 - accuracy: 0.8750\n",
      "Epoch 66: val_loss improved from 1.35964 to 1.34353, saving model to saved_models/audio_classification.hdf5\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.7516 - accuracy: 0.7335 - val_loss: 1.3435 - val_accuracy: 0.9068\n",
      "Epoch 67/100\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 1.6475 - accuracy: 0.7500\n",
      "Epoch 67: val_loss improved from 1.34353 to 1.32262, saving model to saved_models/audio_classification.hdf5\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.7017 - accuracy: 0.7313 - val_loss: 1.3226 - val_accuracy: 0.9153\n",
      "Epoch 68/100\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 1.6438 - accuracy: 0.8125\n",
      "Epoch 68: val_loss improved from 1.32262 to 1.31588, saving model to saved_models/audio_classification.hdf5\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.6839 - accuracy: 0.7186 - val_loss: 1.3159 - val_accuracy: 0.8983\n",
      "Epoch 69/100\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 1.5385 - accuracy: 0.8125\n",
      "Epoch 69: val_loss did not improve from 1.31588\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 1.6958 - accuracy: 0.7249 - val_loss: 1.3285 - val_accuracy: 0.8814\n",
      "Epoch 70/100\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 2.1026 - accuracy: 0.5625\n",
      "Epoch 70: val_loss did not improve from 1.31588\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 1.7243 - accuracy: 0.7505 - val_loss: 1.3201 - val_accuracy: 0.8475\n",
      "Epoch 71/100\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 2.0194 - accuracy: 0.6875\n",
      "Epoch 71: val_loss improved from 1.31588 to 1.28519, saving model to saved_models/audio_classification.hdf5\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.7124 - accuracy: 0.7356 - val_loss: 1.2852 - val_accuracy: 0.9237\n",
      "Epoch 72/100\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 1.6227 - accuracy: 0.6875\n",
      "Epoch 72: val_loss improved from 1.28519 to 1.28321, saving model to saved_models/audio_classification.hdf5\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.6779 - accuracy: 0.7463 - val_loss: 1.2832 - val_accuracy: 0.9237\n",
      "Epoch 73/100\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 1.3138 - accuracy: 0.8750\n",
      "Epoch 73: val_loss improved from 1.28321 to 1.25776, saving model to saved_models/audio_classification.hdf5\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.6501 - accuracy: 0.7569 - val_loss: 1.2578 - val_accuracy: 0.9068\n",
      "Epoch 74/100\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 1.5719 - accuracy: 0.7500\n",
      "Epoch 74: val_loss improved from 1.25776 to 1.24612, saving model to saved_models/audio_classification.hdf5\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.5989 - accuracy: 0.7569 - val_loss: 1.2461 - val_accuracy: 0.9068\n",
      "Epoch 75/100\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 1.6620 - accuracy: 0.6875\n",
      "Epoch 75: val_loss did not improve from 1.24612\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 1.6178 - accuracy: 0.7633 - val_loss: 1.2471 - val_accuracy: 0.9407\n",
      "Epoch 76/100\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 1.9684 - accuracy: 0.6250\n",
      "Epoch 76: val_loss did not improve from 1.24612\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.6684 - accuracy: 0.7505 - val_loss: 1.2464 - val_accuracy: 0.9237\n",
      "Epoch 77/100\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 1.5280 - accuracy: 0.7500\n",
      "Epoch 77: val_loss improved from 1.24612 to 1.21924, saving model to saved_models/audio_classification.hdf5\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.5395 - accuracy: 0.7868 - val_loss: 1.2192 - val_accuracy: 0.9322\n",
      "Epoch 78/100\n",
      " 6/30 [=====>........................] - ETA: 0s - loss: 1.4897 - accuracy: 0.8125\n",
      "Epoch 78: val_loss did not improve from 1.21924\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.5556 - accuracy: 0.7697 - val_loss: 1.2255 - val_accuracy: 0.9068\n",
      "Epoch 79/100\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 1.2587 - accuracy: 0.8750\n",
      "Epoch 79: val_loss improved from 1.21924 to 1.20039, saving model to saved_models/audio_classification.hdf5\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.5823 - accuracy: 0.7569 - val_loss: 1.2004 - val_accuracy: 0.9322\n",
      "Epoch 80/100\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 1.4571 - accuracy: 0.8125\n",
      "Epoch 80: val_loss did not improve from 1.20039\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.5710 - accuracy: 0.7655 - val_loss: 1.2171 - val_accuracy: 0.9068\n",
      "Epoch 81/100\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 1.4320 - accuracy: 0.7500\n",
      "Epoch 81: val_loss improved from 1.20039 to 1.18886, saving model to saved_models/audio_classification.hdf5\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.5715 - accuracy: 0.7633 - val_loss: 1.1889 - val_accuracy: 0.9237\n",
      "Epoch 82/100\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 1.4785 - accuracy: 0.7500\n",
      "Epoch 82: val_loss did not improve from 1.18886\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.5728 - accuracy: 0.7612 - val_loss: 1.2021 - val_accuracy: 0.9322\n",
      "Epoch 83/100\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 1.4074 - accuracy: 0.8125\n",
      "Epoch 83: val_loss did not improve from 1.18886\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 1.5401 - accuracy: 0.7825 - val_loss: 1.2086 - val_accuracy: 0.9322\n",
      "Epoch 84/100\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 1.5521 - accuracy: 0.7500\n",
      "Epoch 84: val_loss improved from 1.18886 to 1.18029, saving model to saved_models/audio_classification.hdf5\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.6018 - accuracy: 0.7740 - val_loss: 1.1803 - val_accuracy: 0.9407\n",
      "Epoch 85/100\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 1.6981 - accuracy: 0.6875\n",
      "Epoch 85: val_loss did not improve from 1.18029\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.5555 - accuracy: 0.7527 - val_loss: 1.1948 - val_accuracy: 0.8898\n",
      "Epoch 86/100\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 1.3063 - accuracy: 0.9375\n",
      "Epoch 86: val_loss did not improve from 1.18029\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 1.4963 - accuracy: 0.7697 - val_loss: 1.1856 - val_accuracy: 0.9068\n",
      "Epoch 87/100\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 1.6383 - accuracy: 0.7500\n",
      "Epoch 87: val_loss improved from 1.18029 to 1.16646, saving model to saved_models/audio_classification.hdf5\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.5967 - accuracy: 0.7420 - val_loss: 1.1665 - val_accuracy: 0.9407\n",
      "Epoch 88/100\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 1.2806 - accuracy: 0.9375\n",
      "Epoch 88: val_loss did not improve from 1.16646\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 1.5969 - accuracy: 0.7655 - val_loss: 1.2730 - val_accuracy: 0.8559\n",
      "Epoch 89/100\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 1.3571 - accuracy: 0.8125\n",
      "Epoch 89: val_loss improved from 1.16646 to 1.15654, saving model to saved_models/audio_classification.hdf5\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.5406 - accuracy: 0.7697 - val_loss: 1.1565 - val_accuracy: 0.9153\n",
      "Epoch 90/100\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 1.2891 - accuracy: 0.8750\n",
      "Epoch 90: val_loss improved from 1.15654 to 1.13832, saving model to saved_models/audio_classification.hdf5\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.4606 - accuracy: 0.7953 - val_loss: 1.1383 - val_accuracy: 0.9153\n",
      "Epoch 91/100\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 1.2293 - accuracy: 0.8750\n",
      "Epoch 91: val_loss improved from 1.13832 to 1.12967, saving model to saved_models/audio_classification.hdf5\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.5370 - accuracy: 0.7804 - val_loss: 1.1297 - val_accuracy: 0.9322\n",
      "Epoch 92/100\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 1.3904 - accuracy: 0.7500\n",
      "Epoch 92: val_loss did not improve from 1.12967\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 1.5754 - accuracy: 0.7676 - val_loss: 1.1368 - val_accuracy: 0.9237\n",
      "Epoch 93/100\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 1.6260 - accuracy: 0.7500\n",
      "Epoch 93: val_loss improved from 1.12967 to 1.09608, saving model to saved_models/audio_classification.hdf5\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.5209 - accuracy: 0.7846 - val_loss: 1.0961 - val_accuracy: 0.9237\n",
      "Epoch 94/100\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 1.5139 - accuracy: 0.8125\n",
      "Epoch 94: val_loss improved from 1.09608 to 1.08177, saving model to saved_models/audio_classification.hdf5\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.5130 - accuracy: 0.7846 - val_loss: 1.0818 - val_accuracy: 0.9407\n",
      "Epoch 95/100\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 1.5435 - accuracy: 0.7500\n",
      "Epoch 95: val_loss did not improve from 1.08177\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 1.4861 - accuracy: 0.7996 - val_loss: 1.0860 - val_accuracy: 0.9492\n",
      "Epoch 96/100\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 1.0290 - accuracy: 1.0000\n",
      "Epoch 96: val_loss improved from 1.08177 to 1.07530, saving model to saved_models/audio_classification.hdf5\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.4536 - accuracy: 0.8060 - val_loss: 1.0753 - val_accuracy: 0.9237\n",
      "Epoch 97/100\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 1.5061 - accuracy: 0.8125\n",
      "Epoch 97: val_loss did not improve from 1.07530\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.4713 - accuracy: 0.7932 - val_loss: 1.1282 - val_accuracy: 0.9068\n",
      "Epoch 98/100\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 1.4278 - accuracy: 0.8750\n",
      "Epoch 98: val_loss did not improve from 1.07530\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 1.4901 - accuracy: 0.7974 - val_loss: 1.0808 - val_accuracy: 0.9237\n",
      "Epoch 99/100\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 1.8669 - accuracy: 0.8125\n",
      "Epoch 99: val_loss improved from 1.07530 to 1.07270, saving model to saved_models/audio_classification.hdf5\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.4114 - accuracy: 0.8081 - val_loss: 1.0727 - val_accuracy: 0.9576\n",
      "Epoch 100/100\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 1.6144 - accuracy: 0.7500\n",
      "Epoch 100: val_loss improved from 1.07270 to 1.04562, saving model to saved_models/audio_classification.hdf5\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.4061 - accuracy: 0.8316 - val_loss: 1.0456 - val_accuracy: 0.9407\n",
      "Training completed in time:  0:00:06.146861\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "num_batch_size = 16\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/audio_classification.hdf5',\n",
    "                               verbose=1, save_best_only=True)\n",
    "start = datetime.now()\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(X_test, y_test), callbacks=[checkpointer], verbose=1)\n",
    "\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(\"Training completed in time: \", duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "\n",
    "def features_extractor(audio_path):\n",
    "    audio, sample_rate = librosa.load(audio_path, res_type='scipy')\n",
    "    mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "    mfccs_scaled_features = np.mean(mfccs_features.T,axis=0)\n",
    "\n",
    "    return mfccs_scaled_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 133ms/step\n",
      "Predicted Label: [2]\n",
      "Prediction Class: ['bhairavi']\n"
     ]
    }
   ],
   "source": [
    "filename = \"./raaga/bhairavi/bhairavi_1.wav\"\n",
    "mfccs_scaled_features = features_extractor(filename)\n",
    "mfccs_scaled_features = mfccs_scaled_features.reshape(1, -1)\n",
    "\n",
    "predictions = model.predict(mfccs_scaled_features)\n",
    "predicted_label = np.argmax(predictions, axis=1)\n",
    "\n",
    "prediction_class = labelencoder.inverse_transform(predicted_label)\n",
    "\n",
    "print(\"Predicted Label:\", predicted_label)\n",
    "print(\"Prediction Class:\", prediction_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step\n",
      "Predicted Label: [6]\n",
      "Prediction Class: ['dkanada']\n"
     ]
    }
   ],
   "source": [
    "filename = \"./raaga/dkanada/dkanada_2.wav\"\n",
    "\n",
    "mfccs_scaled_features = features_extractor(filename)\n",
    "mfccs_scaled_features = mfccs_scaled_features.reshape(1, -1)\n",
    "\n",
    "predictions = model.predict(mfccs_scaled_features)\n",
    "predicted_label = np.argmax(predictions, axis=1)\n",
    "\n",
    "prediction_class = labelencoder.inverse_transform(predicted_label)\n",
    "\n",
    "print(\"Predicted Label:\", predicted_label)\n",
    "print(\"Prediction Class:\", prediction_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
